---
date: 2026-01-12
topic: "Adding Context and Impact to Portfolio Vignettes"
tags: [research, portfolio, feedback-synthesis, hiring-manager-perspective, case-study-design]
status: in-progress
last_updated: 2026-01-12
last_updated_by: claude
---

# Research: Adding Context and Impact to Portfolio Vignettes

Three design professionals (2 design managers, 1 lead designer) reviewed the portfolio and rated it 3-4/5. The craft and interactive approach are praised, but all three independently identified the same gap: **the work shows what was built, but not the thinking, constraints, or outcomes that would signal lead-level design.**

## Core Finding

The portfolio currently reads as "highly skilled senior" rather than "lead." This isn't about adding more content—it's about reframing existing content to show influence, decisions, and impact.

| What Exists | What's Missing |
|-------------|----------------|
| Problem statement (1 sentence) | Business context, constraints, urgency |
| Solution statement (1 sentence) | Trade-offs considered, decisions made |
| Design notes (UI annotations) | Process insights, research findings |
| Adoption stats (some vignettes) | Outcomes, behavioral shifts, strategic impact |
| Strong craft | Evidence of leadership and influence |

---

## Feedback Synthesis

### Reviewer 1 (Rating: 4/5)
> "Getting a sense of the setting, the challenges, business context and maybe describe impact or how it solves the problem for people who aren't familiar with the problem space. In a way that doesn't make it too crowded with words."

**Translation:** Add context and impact, but preserve the concise format.

### Reviewer 2 (Rating: 3/5)
> "The problem/solution descriptions are quite high level, and the visuals abstracted—so I didn't get a good sense of the detail of work in a real context... I didn't get a sense of the problem space/trade-offs/process etc. to get a sense of how you think and work with real world constraints."

**Translation:** Show decision-making and constraints, not just outcomes.

### Reviewer 3 (Rating: 4/5)
> "The craft is super strong, but I want something beyond just excellent production. Right now it reads a little like a very highly skilled senior... the most effective showcases I've seen usually have just slightly more context and impact narrative, not just problem/solution."

> "I want to know more about you and your unique approach to design... Right now it's feeling like your identity is 'I like making AI stuff', which is fine, but as a hiring manager I want to know why and what motivates you around that."

**Translation:** Show outcomes and strategic thinking. Answer "why you?"

---

## Hiring Manager Research: What "Lead-Level" Means in a Portfolio

Research across hiring manager interviews, design leadership articles, and portfolio reviews reveals consistent patterns for what separates senior from lead portfolios.

### The Senior vs Lead Distinction

| Senior Portfolio Shows | Lead Portfolio Shows |
|------------------------|----------------------|
| Expert craft | Vision and strategic direction |
| Deep product knowledge | Cross-team influence |
| Complex problem-solving | Organizational coordination |
| Individual ownership | Team enablement |
| Immediate priorities (0-6 months) | Long-term thinking (12+ months) |
| "I designed this feature" | "This changed how the team/org works" |

### What Hiring Managers Actually Look For

From research across multiple sources:

1. **Leadership signals over pure craft** — "Hiring managers expect strong design skills—it's leadership skills that really differentiate a senior portfolio from a junior one."

2. **Strategic decision-making** — "The working out is 90% of it—what decisions did you make and why? I want to see all those decisions articulated."

3. **Honest attribution** — "It may have been a group effort and that is fine—be honest about your contribution."

4. **Impact framing** — "Show the results first. Hiring managers are busy. If you show results first, they'll be more inclined to find out how you got there."

5. **The About page matters** — "The About page is the first place they click once they've decided your work is solid. They're no longer evaluating your process; they're evaluating you."

### The 6-8 Second Reality

Hiring managers spend 6-8 seconds on initial portfolio scans. The vignette format is well-suited for this—but the opening framing must signal business impact, not just project description.

### How to Signal Lead Level

1. **Show T-shaped leadership** — Breadth across responsibilities AND depth for outsized impact
2. **Include leadership artifacts** — Process improvements, strategic planning, knowledge-sharing
3. **Demonstrate influence** — Stakeholder management, building credibility, changing minds
4. **Show team-level outcomes** — Did you influence other projects? Change the design system? Shift company strategy?
5. **Company-first framing** — Multi-scale impact: business + users + team + culture

---

## The Three Missing Layers

Based on feedback and research, the vignettes need three additional content layers:

### Layer 1: Context (the "before")

**Answers:** Who, where, why now, what constraints?

**Current state:**
> "Synthesizing feedback was the most time-intensive part of performance reviews"

**What's missing:**
- Who experiences this? (Managers? HR? Both?)
- How time-intensive? (Hours? Days per review?)
- Why was this a priority now?
- What constraints shaped the timeline?

**Good context is specific and brief:**
> "Enterprise customers. Managers spending 2+ hours per direct report. Research showed they were already using ChatGPT as a workaround."

### Layer 2: Decisions & Trade-offs (the "how")

**Answers:** What did you consider? What did you decide against? Why?

Design notes currently focus on UI decisions:
> "Tuned the prompts to include specifics like project names, based on user feedback"

**What's missing:**
- What alternatives were on the table?
- What research led to this direction?
- What did you advocate for that wasn't obvious?

**Good decision framing shows thinking:**
> "PM wanted to cut verification features to hit the deadline. Research showed trust was the blocker, not speed. Advocated to keep it—became the pattern for all AI features."

### Layer 3: Impact (the "after")

**Answers:** What changed? For whom? By how much?

**Impact options, ranked by strength:**

| Type | Example | Strength |
|------|---------|----------|
| Hard metrics | "60% reduction in synthesis time" | Strongest |
| Adoption numbers | "12 designers, 30 prototypes created" | Strong |
| Behavioral shift | "Managers went from avoiding AI to requesting it" | Good |
| Strategic outcome | "Findings changed the H2 roadmap" | Good |
| Process change | "Became the standard pattern for AI features" | Acceptable |

**When you don't have metrics:**
> "Success criteria doesn't always have to be metrics—it can be landing a client, launching to get more investors onboard, etc. Showing the thinking alone gets you 80% of the way there."

---

## What the Research Validates

The vignette approach is the right direction. Research confirms:

- **60-80% visuals, 20-40% text** is the recommended ratio
- **Interactive, explorable experiences** are praised over static case studies
- **Compact format** respects the 6-8 second attention span
- **Show don't tell** is explicitly validated for senior portfolios

The format isn't the problem. The content framing is.

---

## Visual Hierarchy Feedback

Reviewer 3 also noted:
> "There's something a bit unresolved for me in the visual hierarchy. Once I start clicking around I kind of just want to keep clicking rather than taking each project in. I think having several primary actions visible at once contributes to that."

This is a separate issue from content depth, but worth noting for a future pass.

---

## Worksheet: Vignette Content Audit

Fill this out for each vignette to identify what's missing.

### AI Highlights

**Current problem statement:**
> Synthesizing feedback was the most time-intensive part of performance reviews

**Current solution statement:**
> Designed AI summaries managers could verify and trust

**Context:**
- Who experienced this problem? (Role, company type)
    - Managers who were completing performance reviews.
    - This was generally professional managers doing performance reviews.
    - For managers who complete reviews, this came up as one of the most time
        consuming and cognitively intense parts of the process.
- What triggered this work? Why now?
    - I don't have a great answer for this but basically the company wanted to
        do AI features.
    - We basically undertook a search for AI problems that could be solved and
        this was done.
    - I wasn't part of the team that did the initial discovery, rather I
        polished it .
- What constraint most shaped the solution?
    - We thought a lot about how much human judgement would play into this.
    - Even though we knew that this would make managers lazy, we wanted to build
        in affordances for people to verify that the AI reported the right
        information. That's why we prioritised the easy access to the actual
        sources.
- How long did you have? Team size?
    - Can't remember but it was over a couple of months.
    - Standard team of Product Manager, Product Designer (myself), Data
        Scientist, FE engineers & BE engineers.
    - There was also a lot of exec oversight and approvals since this was a hot
        project.

**Decisions:**
- What alternatives did you consider?
    - This was a project that had layers and layers of exec indecision.
    - The core of the feature was not changed too much.
    - What I did was refine it, and basically do a lot of exec presentations to
    make sure that this went through.
- What did you advocate for that wasn't obvious?
    - The previous designer who worked on it just did generic screens of the
        interface. E.g. a theme, a summary, etc
    - What I did was really think about the way that it was presented. E.g.
        "Highlights and Opportunities" instead of just "Feedback summary". I
        also paid close attention to the way that the content was
        structured,e.g. making sure it had a narrative angle.
    - I also brought a more human feel to the summaries. e.g how we use avatars
        to indicate that the sources are people rather than just "sources".
- What research changed your direction?
    - Customer feedback indicated that the ai insights were too generic, so i
        worked with the data scientist to make them specific. This is what one
        of the design notes is trying to say.

**Impact:**
- What's the strongest outcome you can claim?
    - Great customer feedback, one quote said that for the type of task, it's
        "just the right amount of AI"
    - 100% positive feedback when using the thumbs
- Did this influence anything beyond the feature?
    - The strucuture of "highligths and opportunities" was then adopted by
        Coach, our conversational AI assistant.

---

### AI Suggestions

**Current problem statement:**
> (Fill in from content.ts)

**Current solution statement:**
> (Fill in from content.ts)

**Context:**
- Who experienced this problem?
    - We knew that managers were not great at feedback, and we know that the way
        feedback is written is very important.
    - However, like the previous one, this was an exec driven AI feature that we
        released.
- What triggered this work?
    - See above
- What constraint shaped the solution?
    - Again, trying to respect agency of the manager, how do we design somthing
        that encourages critical thinking, not just having the AI do it all.
- Timeline / team size?
    - Same as the previous.

**Decisions:**
- What alternatives did you consider?
    - We considered more active and not active methods of doing suggestions.
    - But again, exec indecision made this project very hard.
- What did you advocate for?
    - I advocated for the simple way to activate the feature.
    - E.g. how the improve button is placed in the rich text editor.

**Impact:**
- Strongest outcome?
    - ~80% of people who pressed the Improve button made a change to their
        feedback after use.
- Observable change?
    - See above
- Influence beyond the feature?
    - I designed the AI gradient pattern as a signiifer of AI features at
        Culture Amp.
    - This spread to other features.
- Pattern others adopted?
    - See above

---

### Prototyping (Design Sandbox)

**Current problem statement:**
> Designers had no shared foundation for AI prototyping

**Current solution statement:**
> A shared sandbox that makes AI prototyping easy

**Existing impact data:**
> 12 designers, 30 prototypes

**Context:**
- Who experienced this problem?
    - I experienced this problem first, I was doing a lot of vibe-coded
        prototypes and found that I was missing an organisational layer for it.
    - I also couldn't figure out a way to deploy this to our infra so that it
        can be shared with people
- What triggered this work?
    - My own experience
- What constraint shaped the solution?
    - I was a single designer who solved problems for myself.
- Timeline / team size?
    - Mostly myself with some support from the developer experience team.

**Decisions:**
- What alternatives did you consider?
    - Things like Gemini, Replit etc but our existing AI tools were nothing
        compared to an actual coding agent. And we didn't have budget for things
        like Replit but we did have access to coding agents.
- What did you advocate for?
    - I just did it

**Impact:**
- Beyond adoption numbers, what changed?
    - This is a bit high-horsey but I do think I kicked off a bigger culture of
        Ai prototyoing at Culture Amp. I did a lot of sharing, documentation
        and walking through the team to onboard this tool.
- Did this influence team process?
    - Yes, a singificant feature for another team was prototypes using this
        feature.
- Did this become org-wide?
    - Kinda, everyone can use it!

---

### Multilingual (Translation Management)

**Current problem statement:**
> Supporting multiple languages required a separate workflow for each language

**Current solution statement:**
> Designed a simple way to bring multiple languages into a single cycle

**Context:**
- Who experienced this problem?
    - Multinational orgs that used Culture Amp had to manage like multiple
        cycles in order to run their performance cycles.
- What triggered this work?
    - It was a significant blocker for our larger customers. It was a painpoint
        for a significant amount of ARR.
- What constraint shaped the solution?
    - We had to make it feel familiar to the existing performance cycles
        workflow. So it fits in with the flow and feels like a natural extension
        of it rather than a new flow.
- Timeline / team size?
    - A couple of months of discovery, testing & iterating.
    - PM, Tech Lead, Design (me) and devs

**Decisions:**
- What did you advocate for?
    - Machine translation and Excel were not in the original scope.
- What research informed this?
    - Because we found that these two things were an established part of their
        processes.

**Impact:**
- Strongest outcome?
    - Ongoing active usage of a significant feature with 0 support tickets. I
        think thhat this was because it was super easy to use.
- Observable change?
    - People were using it.
- Influence beyond the feature?
    - Our Multilingual implemntation was so good that it set the benchmark for
        customers. They asked for the same process in other parts of the
        product.

---

### Home Connect

**Current problem statement:**
> (Fill in from content.ts)

**Current solution statement:**
> (Fill in from content.ts)

**Context:**
- Who experienced this problem?
- What triggered this work?
- What constraint shaped the solution?
- Timeline / team size?

**Decisions:**
- What alternatives did you consider?
- What did you advocate for?
- What research informed this?
- What did you decide against?

**Impact:**
- Strongest outcome?
- Observable change?
- Influence beyond the feature?

---

### Vibe Coding

**Current problem statement:**
> (Fill in from content.ts)

**Current solution statement:**
> (Fill in from content.ts)

**Context:**
- What motivated this personal project?
- What were you trying to learn/prove?

**Decisions:**
- What approach did you take?
- What surprised you?

**Impact:**
- What did you learn?
- How does this connect to your professional work?

---

## Identity Questions (For About Section)

Reviewer 3: "I want to know more about you and your unique approach to design."

- Why AI? What draws you to this space?
- What's your design philosophy in one sentence?
- What do you believe that most designers don't?
- What's a hill you'd die on?
- What kind of problems energize you?

---

## Next Steps

1. **Fill out the worksheet** for each vignette
2. **Prioritize 2-3 vignettes** that have the strongest answers
3. **Draft new content** for those vignettes first
4. **Test with 1-2 people** before rolling out to all vignettes
5. **Address identity questions** for About section (separate effort)

---

## Sources

- Feedback CSV from portfolio survey (3 respondents, Jan 7-9 2026)
- [The Crucial First Impression - Medium](https://medium.com/design-bootcamp/the-crucial-first-impression-what-hiring-managers-look-for-in-product-design-portfolios-553e6a865ee9)
- [What a Hiring Manager Looks For - Leslie Yang](https://leslieyang.substack.com/p/what-a-hiring-manager-looks-for-in)
- [How Recruiters Actually Look at Your Portfolio](https://blog.opendoorscareers.com/p/how-recruiters-and-hiring-managers-actually-look-at-your-portfolio)
- [Impact-First Storytelling in Your Product Design Portfolio](https://medium.com/@sarahscussel/impact-first-storytelling-in-your-product-design-portfolio-9f122f747ee8)
- [What's the Difference Between Lead, Staff, and Principal Designer?](https://newsletter.uxdesign.cc/p/whats-the-difference-between-lead)
- [Three Tips on Design Leaders' Portfolio Presentations - DoorDash](https://medium.com/design-doordash/three-tips-on-design-leaders-portfolio-presentations-5afd4e412bf8)
- [4 Product Design Portfolio Mistakes - Medium](https://medium.com/design-bootcamp/4-product-design-ux-portfolio-mistakes-that-silently-ruin-your-job-search-3e6a666a48e7)
